# Descrição de Gestos em ASL por LLM: Uma Abordagem via Prompting com Gemini

Este projeto demonstra a integração entre Modelos de Linguagem de Grande Escala (LLMs – Large Language Models) e modelos de visão computacional. Utilizamos uma rede neural convolucional (CNN) para classificar imagens de gestos da Língua de Sinais Americana (ASL), identificando as letras e números correspondentes. A sequência prevista é então passada como entrada para Gemini que por meio de técnicas de prompting, gera descrições textuais de como realizar cada gesto em ASL. Esse tipo de aplicação pode contribuir para a melhoria da comunicação entre pessoas com e sem deficiência auditiva.

O notebook base utilizado para treinar o modelo CNN foi retirado do Kaggle e está disponível em: https://www.kaggle.com/code/sachinpatil1280/hand-sign-multi-class-classification-cnn-97 – de autoria de Sachin Patil.

![asl](https://github.com/user-attachments/assets/a8410f9f-b9c1-4df4-8f7f-f836ee448c19)
